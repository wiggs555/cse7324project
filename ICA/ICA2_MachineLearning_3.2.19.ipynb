{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href='https://fonts.googleapis.com/css?family=Passion+One' rel='stylesheet' type='text/css'><style>div.attn { font-family: 'Helvetica Neue'; font-size: 30px; line-height: 40px; color: #FFFFFF; text-align: center; margin: 30px 0; border-width: 10px 0; border-style: solid; border-color: #5AAAAA; padding: 30px 0; background-color: #DDDDFF; }hr { border: 0; background-color: #ffffff; border-top: 1px solid black; }hr.major { border-top: 10px solid #5AAA5A; }hr.minor { border: none; background-color: #ffffff; border-top: 5px dotted #CC3333; }div.bubble { width: 65%; padding: 20px; background: #DDDDDD; border-radius: 15px; margin: 0 auto; font-style: italic; color: #f00; }em { color: #AAA; }div.c1{visibility:hidden;margin:0;height:0;}div.note{color:red;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Ebnable HTML/CSS \n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<link href='https://fonts.googleapis.com/css?family=Passion+One' rel='stylesheet' type='text/css'><style>div.attn { font-family: 'Helvetica Neue'; font-size: 30px; line-height: 40px; color: #FFFFFF; text-align: center; margin: 30px 0; border-width: 10px 0; border-style: solid; border-color: #5AAAAA; padding: 30px 0; background-color: #DDDDFF; }hr { border: 0; background-color: #ffffff; border-top: 1px solid black; }hr.major { border-top: 10px solid #5AAA5A; }hr.minor { border: none; background-color: #ffffff; border-top: 5px dotted #CC3333; }div.bubble { width: 65%; padding: 20px; background: #DDDDDD; border-radius: 15px; margin: 0 auto; font-style: italic; color: #f00; }em { color: #AAA; }div.c1{visibility:hidden;margin:0;height:0;}div.note{color:red;}</style>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Enter Team Member Names here (*double click to edit*):\n",
    "\n",
    "- Name 1: Thomas Adams\n",
    "- Name 2: Suleiman Hijazeen\n",
    "- Name 3: Nancy Le\n",
    "- Name 4: Andrew Whigham\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Class Assignment Two\n",
    "In the following assignment you will be asked to fill in python code and derivations for a number of different problems. Please read all instructions carefully and turn in the rendered notebook (or HTML of the rendered notebook)  before the end of class (or right after class). The initial portion of this notebook is given before class and the remainder is given during class. Please answer the initial questions before class, to the best of your ability. Once class has started you may rework your answers as a team for the initial part of the assignment. \n",
    "\n",
    "<a id=\"top\"></a>\n",
    "## Contents\n",
    "* <a href=\"#Loading\">Loading the Data</a>\n",
    "* <a href=\"#svm\">Linear SVMs</a>\n",
    "* <a href=\"#svm_using\">Using Linear SVMs</a>\n",
    "* <a href=\"#nonlinear\">Non-linear SVMs</a>\n",
    "\n",
    "________________________________________________________________________________________________________\n",
    "\n",
    "<a id=\"Loading\"></a>\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "## Loading the Data\n",
    "Please run the following code to read in the \"olivetti faces\" dataset from sklearn's data loading module. \n",
    "\n",
    "This will load the data into the variable `ds`. `ds` is a `bunch` object with fields like `ds.data` and `ds.target`. The field `ds.data` is a numpy matrix of the continuous features in the dataset. **The object is not a pandas dataframe. It is a numpy matrix.** Each row is a set of observed instances, each column is a different feature. It also has a field called `ds.target` that is an integer value we are trying to predict (i.e., a specific integer represents a specific person). Each entry in `ds.target` is a label for each row of the `ds.data` matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the images for the dataset\n",
    "# this will take a long time the first run because it needs to download\n",
    "# after the first time, the dataset will be save to your disk (in sklearn package somewhere) \n",
    "# if this does not run, you may need additional libraries installed on your system (install at your own risk!!)\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=20, resize=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 3023\n",
      "n_features: 11750\n",
      "n_classes: 62\n",
      "Original Image Sizes 125 by 94\n",
      "11750\n"
     ]
    }
   ],
   "source": [
    "# get some of the specifics of the dataset\n",
    "X = lfw_people.data\n",
    "y = lfw_people.target\n",
    "names = lfw_people.target_names\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "_, h, w = lfw_people.images.shape\n",
    "n_classes = len(names)\n",
    "\n",
    "\n",
    "\n",
    "print(\"n_samples: {}\".format(n_samples))\n",
    "print(\"n_features: {}\".format(n_features))\n",
    "print(\"n_classes: {}\".format(n_classes))\n",
    "print(\"Original Image Sizes {} by {}\".format(h,w))\n",
    "print (125*94) # the size of the images are the size of the feature vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** For the faces dataset, describe what the data represents? That is, what is each column? What is each row? What do the unique class values represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each column represents a pixel as a feature. Each row is an instance of the data - a specific image. Since there are 3023 samples in the dataset, there are 3023 rows. Since the images are 125 by 94 pixels, we have 125 * 94 = 11750 columns of features.\n",
    "\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"svm\"></a>\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "## Linear Support Vector Machines\n",
    "\n",
    "**Question 2:** If we were to train a linear Support Vector Machine (SVM) upon the faces data, how many parameters would need to be optimized in the model? That is, how many coefficients would need to be calculated?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would need the same number of parameters as features for each classifier, which would by 125 * 94 = 11750 coefficients per classifier. Depending on whether we are using One-Vs-All or One-Vs-One, we would have either:\n",
    "\n",
    "One-Vs-All:\n",
    "\n",
    "    62 classifiers......      (n_classes) \n",
    "\n",
    "or \n",
    "\n",
    "One-Vs-One:\n",
    "\n",
    "    1,891 classifiers....     (n_classes * (n_classes - 1) / 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00233145  0.00089948 -0.00184752 ...  0.01409334  0.00074242\n",
      "  -0.00358786]\n",
      " [-0.04148765 -0.03136253 -0.01567535 ...  0.044099    0.02492506\n",
      "   0.00118109]\n",
      " [ 0.01599051  0.0265195   0.03556783 ...  0.00647601  0.01674502\n",
      "   0.01670068]\n",
      " ...\n",
      " [-0.0053116  -0.0162482  -0.0188582  ...  0.01449738  0.03493597\n",
      "   0.05328726]\n",
      " [ 0.10930735  0.03130511 -0.0249525  ...  0.04288251  0.02474159\n",
      "  -0.01944119]\n",
      " [-0.02639129 -0.0184326  -0.01059024 ... -0.02820624 -0.02604045\n",
      "  -0.02366287]]\n",
      "Wall time: 8min 43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Enter any scratchwork or calculations here\n",
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC()\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(clf.coef_)\n",
    "\n",
    "#This strategy, also known as one-vs-all, is implemented in OneVsRestClassifier. \n",
    "#The strategy consists in fitting one classifier per class. For each classifier, \n",
    "#the class is fitted against all the other classes. In addition to its computational \n",
    "#efficiency (only n_classes classifiers are needed), one advantage of this approach is \n",
    "#its interpretability. Since each class is represented by one and only one classifier, \n",
    "#it is possible to gain knowledge about the class by inspecting its corresponding classifier.\n",
    "#This is the most commonly used strategy and is a fair default choice.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62, 11750)\n"
     ]
    }
   ],
   "source": [
    "print(clf.coef_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:** \n",
    "- **Part A:** Given the number of parameters calculated above, would you expect the model to train quickly using **batch optimization techniques**? Why or why not? \n",
    "- **Part B:** Is there a way to reduce training time?\n",
    "- **Part C:** If we transformed the X data using principle components analysis (PCA) with 100 components, how many parameters would we need to find for a linear Support Vector Machine (SVM)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Enter you answer here (double click)*\n",
    "\n",
    "\n",
    "A. No, there are too many features to quickly compute SVCs.\n",
    "\n",
    "B. Yes, if we could reduce the number of dimensions in the dataset before computing our SVCs, it would reduce the computation time.\n",
    "\n",
    "C. 100. By reducing the data to only 100 dimensions, we would only need to calculate 100 parameters for our SVC.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62, 100)\n",
      "Part C. With 100 features:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Enter any scratchwork or calculations here\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "pca.fit(X)\n",
    "X_pca = pca.transform(X)\n",
    "\n",
    "\n",
    "clf_pca = LinearSVC()\n",
    "clf_pca.fit(X_pca, y)\n",
    "\n",
    "\n",
    "print(clf_pca.coef_.shape)\n",
    "\n",
    "\n",
    "print('Part C. With 100 features: ', clf_pca.coef_.shape[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a id=\"svm_using\"></a>\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "\n",
    "# Using Linear SVMs\n",
    "\n",
    "**Exercise 1:** Use the block of code below to check if the number of parameters you calculated is equal to the number of parameters returned by `sklearn`'s implementation of the Linear SVM. **Was your calculation correct? If different, can you think of a reason why the parameters would not match?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n_components = 100\n",
    "pca = PCA(n_components=n_components,svd_solver='randomized')\n",
    "Xpca = pca.fit_transform(X)\n",
    "\n",
    "clf = LinearSVC()\n",
    "clf.fit(Xpca,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62, 100)\n"
     ]
    }
   ],
   "source": [
    "#===================================================================\n",
    "# Enter your code below to calculate the number of parameters in the model \n",
    "\n",
    "print(clf.coef_.shape)\n",
    "\n",
    "#==================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the number of parameters (per classifier) we calculated matched sklearn's implementation of the Linear SVM. If it had not matched, it could be because of a difference in approach (One-Vs-One or One-Vs-All). These produce a difference in the number of classifiers for the resulting matrix, but the number of columns would still be the same - 100. This is because PCA has reduced the dimensionality to 100. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "**Exercise 2:** Use the starter code below to calculate two quantities: \n",
    "- **Part A.:** The overall accuracy of the trained linear svm on the training set\n",
    "- **Part B.:** The *mean, standard deviation, maximum, and minimum* of the **accuracy per class** on the training set\n",
    "\n",
    "You might be interested in the following documentation of the confusion matrix calculated by `scikit-learn`:\n",
    "- http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "And an example matrix returned by the confusion matrix function:\n",
    "<img src=\"http://scikit-learn.org/stable/_images/sphx_glr_plot_confusion_matrix_001.png\",width=400,height=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy is  0.9388025140588819\n",
      "The class accuracy is  0.8966422304532808 +- 0.1398543291869833 (min,max) ( 0.35 1.0 )\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "yhat = clf.predict(Xpca)\n",
    "\n",
    "\n",
    "#===================================================\n",
    "# Enter your code below\n",
    "\n",
    "cm = confusion_matrix(y, yhat)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "diag = np.diagonal(cm)\n",
    "\n",
    "print('Overall Accuracy is ', accuracy_score(y, yhat))\n",
    "\n",
    "\n",
    "print('The class accuracy is ',np.mean(diag), '+-', np.std(diag),end=' ')\n",
    "print('(min,max) (',np.min(diag), np.max(diag),')')\n",
    "\n",
    "#==================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a id=\"nonlinear\"></a>\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "\n",
    "# Non-linear SVMs\n",
    "Now let's explore the use of non-linear svms. More explicitly, using different kernels. Take a look at the example training and testing code below for the non-linear SVM. All parameters are left as default, except we change the kernel to be `rbf`. Run the block of code below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy is  0.9388025140588819\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel='rbf')\n",
    "clf.fit(Xpca,y)\n",
    "yhat = clf.predict(Xpca)\n",
    "accuracy = dict()\n",
    "accuracy['rbf'] = accuracy_score(y,yhat)\n",
    "print('Overall Accuracy is ',accuracy_score(y,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "**Exercise 3:** Use the starter code from above to calculate the accuracy for three different non-linear SVM kernels. That is, repeat the code above for different `kernel` parameters. **Only use non-linear kernels.  Which kernel is most accurate with the default parameters?**\n",
    "\n",
    "You might be interested in the documentation of the scikit-learn SVM implementation, available here:\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#===================================================\n",
    "# Enter your code below\n",
    "clf = SVC(kernel='poly')\n",
    "clf.fit(Xpca,y)\n",
    "yhat = clf.predict(Xpca)\n",
    "accuracy['poly'] = accuracy_score(y,yhat)\n",
    "\n",
    "clf = SVC(kernel='sigmoid')\n",
    "clf.fit(Xpca,y)\n",
    "yhat = clf.predict(Xpca)\n",
    "accuracy['sigmoid'] = accuracy_score(y,yhat)\n",
    "\n",
    "clf = SVC(kernel='precomputed')\n",
    "kernel_train = np.dot(Xpca, Xpca.T)\n",
    "yhat = SVC(kernel='precomputed').fit(kernel_train,y).predict(kernel_train)\n",
    "\n",
    "accuracy['precomputed'] = accuracy_score(y,yhat)\n",
    "\n",
    "#==================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rbf': 0.9388025140588819, 'precomputed': 0.9986768111147867, 'poly': 0.9751902084022495, 'sigmoid': 0.214356599404565}\n",
      "The highest accuracy is:  precomputed 0.9986768111147867\n"
     ]
    }
   ],
   "source": [
    "print (accuracy)\n",
    "\n",
    "maximum = max(accuracy, key=accuracy.get) \n",
    "print('The highest accuracy is: ', maximum, accuracy[maximum])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most accurate kernel is ... Precomputed but second best is poly. Precomputed doesn't seem to fit the intent of this exercise so we are proceeding with Poly for the following exercise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "**Exercise 4:** Choose the **most accurate kernel** and manipulate the settings for `gamma` to make the classification more accurate. \n",
    "- **Part A:** How accurate can you make it? \n",
    "- **Part B:** Would you expect the results to generalize well? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With g =  0.01 Overall Accuracy is  0.9751902084022495\n",
      "With g =  0.02 Overall Accuracy is  1.0\n",
      "With g =  0.03 Overall Accuracy is  1.0\n",
      "With g =  0.04 Overall Accuracy is  1.0\n",
      "With g =  0.05 Overall Accuracy is  1.0\n",
      "With g =  0.060000000000000005 Overall Accuracy is  1.0\n",
      "With g =  0.06999999999999999 Overall Accuracy is  1.0\n",
      "With g =  0.08 Overall Accuracy is  1.0\n",
      "With g =  0.09 Overall Accuracy is  1.0\n",
      "With g =  0.09999999999999999 Overall Accuracy is  1.0\n",
      "With g =  0.11 Overall Accuracy is  1.0\n",
      "With g =  0.12 Overall Accuracy is  1.0\n",
      "With g =  0.13 Overall Accuracy is  1.0\n",
      "With g =  0.14 Overall Accuracy is  1.0\n",
      "With g =  0.15000000000000002 Overall Accuracy is  1.0\n",
      "With g =  0.16 Overall Accuracy is  1.0\n",
      "With g =  0.17 Overall Accuracy is  1.0\n",
      "With g =  0.18000000000000002 Overall Accuracy is  1.0\n",
      "With g =  0.19 Overall Accuracy is  1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "#===================================================\n",
    "# Enter your code below\n",
    "\n",
    "kern = 'poly'\n",
    "g = None\n",
    "\n",
    "for x in numpy.arange(0.01, .20, .01):\n",
    "    yhat = SVC(kernel=kern, gamma=x).fit(Xpca,y).predict(Xpca)\n",
    "    print('With g = ', x, 'Overall Accuracy is ', accuracy_score(y,yhat))     \n",
    "\n",
    "\n",
    "#==================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Enter you answer here (double click)*\n",
    "\n",
    "A. The highest accuracy we could achieve was ... 1.0\n",
    "\n",
    "B. We would not expect this to generalize because it is very trial and error intensive, and compounding this process with large datasets could be computationally expensive. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "**Final Question:** Using the most accurate non-linear SVM you found in the previous question, how many parameter coefficients does the trained model contain?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Enter you answer here (double click)*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61, 2939)\n",
      "The poly SVM contains  2939  parameters.\n"
     ]
    }
   ],
   "source": [
    "#===================================================\n",
    "# Enter any scratchwork calculations you need below\n",
    "polySVC = SVC(kernel=kern, gamma=0.1).fit(Xpca,y)\n",
    "print(polySVC.dual_coef_.shape)\n",
    "print('The poly SVM contains ', polySVC.dual_coef_.shape[1], ' parameters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________\n",
    "\n",
    "That's all! Please **save (make sure you saved!!!) and upload your rendered notebook** and please include **team member names** in the notebook submission."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
