{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CSE 7324 Lab 6: Convolutional Network Architectures**\n",
    "### *Thomas Adams, Suleiman Hijazeen, Nancy Le and Andrew Whigham*\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Preparation**\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "from scipy import ndimage\n",
    "import sys\n",
    "import os\n",
    "from time import time\n",
    "from time import sleep\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "from plotly.graph_objs import Bar, Line\n",
    "from plotly.graph_objs import Scatter, Layout\n",
    "from plotly.graph_objs.scatter import Marker\n",
    "from plotly.graph_objs.layout import XAxis, YAxis\n",
    "import seaborn as sns\n",
    "from IPython.display import Image as _Imgdis\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import datasets as ds\n",
    "import cv2  \n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import average \n",
    "from keras.models import Input, Model\n",
    "\n",
    "keras.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as mt\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.io import imshow\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "def summarize_net(net, X_test, y_test, title_text=''):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    yhat = np.argmax(net.predict(X_test), axis=1)\n",
    "    acc = mt.accuracy_score(y_test,yhat)\n",
    "    cm = mt.confusion_matrix(y_test,yhat)\n",
    "    cm = cm/np.sum(cm,axis=1)[:,np.newaxis]\n",
    "    sns.heatmap(cm, annot=True, fmt='.2f')\n",
    "    plt.title(title_text+'{:.4f}'.format(acc))\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Metric Evaluation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create custom f1 metric from custom recall and precision\n",
    "from keras.layers import concatenate\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred): # recall is true positive / (total actual positive)\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1))) # y_true * y_pred will only give 1 for true positives\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1))) # actual positives are just y_true\n",
    "        # recall is true positive / (total actual positive).. the episol is a small number to prevent divide by zero errors\n",
    "        recall = true_positives / (possible_positives + K.epsilon()) \n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred): #precision is true positives / (total predicted positives)\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1))) # y_true * y_pred will only give 1 for true positives\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1))) # predicted positives\n",
    "        # (true positive / predicted positive).. the episol is a small number to prevent divide by zero errors\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())   \n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred): # f1 = 2 * (precision*recall / precision + recall)\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metric we will use to determine the performance of our model will be the macro-averaged F1 score. We are using macro-averaging instead of micro even though we do not have a class imbalance problem. The number of instances for each class are 3000 \n",
    "\n",
    " in this project we are predecting what latter this sign is for using a set of pictures of ASL signes thus We are using F1 as we care both about precision and recall , either high False Positive or high False Negative leades to missunderstading of a latter that lead to a missunderstading in the whold word or sentenanse.\n",
    "\n",
    "Since keras does not provide recall, precision, or f1 in their metrics package as a result of the 2.0 release, we will need to implement our own custom metric. Keras removed these functions as they are global metrics which were being approximated in batches (as keras runs in batches). However, for our purposes, this approximation will suffice. We found the following post on datascience stackexchange which helped detail this process below. Though fairly straightforward, we have provided comments to explain the code we have leveraged.\n",
    "\n",
    "https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
    "\n",
    "https://github.com/keras-team/keras/wiki/Keras-2.0-release-notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "asl = pd.read_csv(\"data/asl_alphabet_train_50.csv\")\n",
    "\n",
    "y=asl.drop(asl.columns[1:], axis=1)\n",
    "asl=asl.drop(asl.columns[0], axis=1)\n",
    "asl.shape\n",
    "yasl=np.asarray(asl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(yasl.reshape((-1,50,50)), axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Splitting Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69599, 1)\n",
      "(69599, 2500)\n"
     ]
    }
   ],
   "source": [
    "img_wh=50\n",
    "NUM_CLASSES=29\n",
    "X_ar=np.asarray(asl)\n",
    "y_ar=np.asarray(y)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_ar,y_ar, test_size=0.2)\n",
    "X_train_d = np.expand_dims(X_train.reshape((-1,img_wh,img_wh)), axis=3)\n",
    "X_test_d = np.expand_dims(X_test.reshape((-1,img_wh,img_wh)), axis=3)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(X_train.shape)\n",
    "y_train_ohe = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test_ohe = keras.utils.to_categorical(y_test, NUM_CLASSES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the Data\n",
    "Here we will split the training and test datasets. Since we have almost 80k instances of data, the likelihood that we will use ~64k unrepresentative examples is extremely small. Thus, we have opted for the simple 80/20 split.\n",
    "\n",
    "since we got 3000 train picture for each alphabet so I believe this is enough figure to go with a simple 80 20 split  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Modeling**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 CNN with Keras and Data Expansion\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=10, # used, Int. Degree range for random rotations.\n",
    "    width_shift_range=0.1, # used, Float (fraction of total width). Range for random horizontal shifts.\n",
    "    height_shift_range=0.1, # used,  Float (fraction of total height). Range for random vertical shifts.\n",
    "    shear_range=1, # Float. Shear Intensity (Shear angle in counter-clockwise direction as radians)\n",
    "    zoom_range=0.1,#Range for random zoom\n",
    "    channel_shift_range=0.1,#Range for random channel shifts.\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    rescale=None)\n",
    "\n",
    "datagen.fit(X_train_d)\n",
    "\n",
    "idx = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the code above will alter our training data so that for each epoces you are always dealing with new data, we decide to generate different pictures by changing the following:\n",
    "\n",
    "1- rotation_range: which is routing the picture by a certain value of degrees, we decicde to be 10 because more than that might introduce confusion with other ASL signs\n",
    "\n",
    "2- height_shift_range: inducing a random horizontal shifts we decided to stay with .1 (mean shift .1 fraction of the total height ) because we don't to loss any features in the picture by adding high shifts \n",
    "\n",
    "3- width_shift_range: introducing a random vertical shifts we decided to stay with .1 (mean shift .1 fraction of the total width) because we don't lose any features in the picture by adding high shifts \n",
    "\n",
    "4- shear_range: adding a sheer intensity, we believe adding shear will give better mimicry to real cases of destortion to an image \n",
    "\n",
    "5- zoom_range: introducing random zoom which is a good representation to a distortion might happen to a picture where not the whole hand is visible \n",
    "\n",
    "6- channel_shift_range: random channel shifts, this might not affect the picture but we thought its good element to add if colors would be introduced in the future "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train_d[3000].squeeze(),cmap='bone')\n",
    "print(y_train[3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew/anaconda3/envs/mlenv/lib/python3.7/site-packages/skimage/io/_plugins/matplotlib_plugin.py:80: UserWarning:\n",
      "\n",
      "Float image out of standard range; displaying image with stretched contrast.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmps = datagen.flow(X_train_d, y_train_ohe, batch_size=1)\n",
    "\n",
    "for tmp in tmps:\n",
    "    imshow(tmp[0].squeeze(),cmap='bone')\n",
    "   \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Comparing CNNs with Different Parameters\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/andrew/anaconda3/envs/mlenv/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/andrew/anaconda3/envs/mlenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# what if we just want to use the validation data??\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2 \n",
    "l2_lambda = 0.0001\n",
    "\n",
    "# Use Kaiming He to regularize ReLU layers: https://arxiv.org/pdf/1502.01852.pdf\n",
    "# Use Glorot/Bengio for linear/sigmoid/softmax: http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf \n",
    "cnn = Sequential()\n",
    "\n",
    "cnn.add(Conv2D(filters=32,\n",
    "               input_shape = (img_wh,img_wh,1),\n",
    "               kernel_size=(3,3),\n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda),\n",
    "               padding='same', \n",
    "               activation='relu',\n",
    "               data_format=\"channels_last\")) # more compact syntax\n",
    "\n",
    "cnn.add(Conv2D(filters=32,\n",
    "               kernel_size=(3,3),\n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda),\n",
    "               padding='same', \n",
    "               activation='relu',data_format=\"channels_last\"))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\"))\n",
    "\n",
    "cnn.add(Conv2D(filters=64,\n",
    "               input_shape = (img_wh,img_wh,1),\n",
    "               kernel_size=(3,3),\n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda),\n",
    "               padding='same', \n",
    "               activation='relu',data_format=\"channels_last\")) # more compact syntax\n",
    "\n",
    "cnn.add(Conv2D(filters=64,\n",
    "               kernel_size=(3,3),\n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda),\n",
    "               padding='same', \n",
    "               activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\"))\n",
    "\n",
    "cnn.add(Conv2D(filters=128,\n",
    "               input_shape = (img_wh,img_wh,1),\n",
    "               kernel_size=(3,3),\n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda),\n",
    "               padding='same', \n",
    "               activation='relu',data_format=\"channels_last\")) # more compact syntax\n",
    "\n",
    "cnn.add(Conv2D(filters=128,\n",
    "               kernel_size=(3,3),\n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda),\n",
    "               padding='same', \n",
    "               activation='relu',data_format=\"channels_last\"))\n",
    "    \n",
    "\n",
    "# add one layer on flattened output\n",
    "\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dropout(0.25)) # add some dropout for regularization after conv layers\n",
    "cnn.add(Dense(128, \n",
    "              activation='relu',\n",
    "              kernel_initializer='he_uniform',\n",
    "              kernel_regularizer=l2(l2_lambda)\n",
    "       ))\n",
    "cnn.add(Dropout(0.5)) # add some dropout for regularization, again!\n",
    "cnn.add(Dense(NUM_CLASSES, \n",
    "              activation='softmax', \n",
    "              kernel_initializer='glorot_uniform',\n",
    "              kernel_regularizer=l2(l2_lambda)\n",
    "             ))\n",
    "\n",
    "# Let's train the model \n",
    "cnn.compile(loss='categorical_crossentropy', # 'categorical_crossentropy' 'mean_squared_error'\n",
    "              optimizer='rmsprop', # 'adadelta' 'rmsprop'\n",
    "              metrics=['acc', f1_m])\n",
    "\n",
    "# the flow method yields batches of images indefinitely, with the given transofmrations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/andrew/anaconda3/envs/mlenv/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      " 893/2174 [===========>..................] - ETA: 4:19 - loss: 6.5173 - acc: 0.0482 - f1_m: 0.0128"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a1ece7f56860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test_ohe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                   \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m                  )\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlenv/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlenv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlenv/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlenv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlenv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history =cnn.fit_generator(datagen.flow(X_train_d, y_train_ohe, batch_size=32), \n",
    "                  steps_per_epoch=int(len(X_train)/32), # how many generators to go through per epoch\n",
    "                  epochs=50, verbose=1,\n",
    "                  validation_data=(X_test_d,y_test_ohe),\n",
    "                  callbacks=[EarlyStopping(monitor='val_loss', patience=2)]\n",
    "                 )\n",
    "\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_net(cnn, X_test_d, y_test, title_text='Using Expansion:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from keras.layers import average, concatenate\n",
    "from keras.models import Input, Model\n",
    "\n",
    "num_ensembles = 3\n",
    "l2_lambda = 0.000001\n",
    "\n",
    "input_holder = Input(shape=(img_wh, img_wh, 1))\n",
    "\n",
    "# start with a conv layer\n",
    "x = Conv2D(filters=32,\n",
    "               input_shape = (img_wh,img_wh,1),\n",
    "               kernel_size=(3,3),\n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda),\n",
    "               padding='same', \n",
    "               activation='relu', data_format=\"channels_last\")(input_holder)\n",
    "\n",
    "x = Conv2D(filters=32,\n",
    "               kernel_size=(3,3),\n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda),\n",
    "               padding='same', \n",
    "               activation='relu')(x)\n",
    "input_conv = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(x)\n",
    "\n",
    "branches = []\n",
    "for _ in range(num_ensembles):\n",
    "    \n",
    "    # start using NiN (MLPConv)\n",
    "    x = Conv2D(filters=32,\n",
    "                   input_shape = (img_wh,img_wh,1),\n",
    "                   kernel_size=(3,3),\n",
    "                   kernel_initializer='he_uniform', \n",
    "                   kernel_regularizer=l2(l2_lambda),\n",
    "                   padding='same', \n",
    "                   activation='linear', data_format=\"channels_last\")(input_conv)\n",
    "\n",
    "    x = Conv2D(filters=32,\n",
    "                   kernel_size=(1,1),\n",
    "                   kernel_initializer='he_uniform', \n",
    "                   kernel_regularizer=l2(l2_lambda),\n",
    "                   padding='same', \n",
    "                   activation='relu', data_format=\"channels_last\")(x)\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(x)\n",
    "    \n",
    "    x = Conv2D(filters=64,\n",
    "                   input_shape = (img_wh,img_wh,1),\n",
    "                   kernel_size=(3,3),\n",
    "                   kernel_initializer='he_uniform', \n",
    "                   kernel_regularizer=l2(l2_lambda),\n",
    "                   padding='same', \n",
    "                   activation='linear', data_format=\"channels_last\")(x)\n",
    "\n",
    "    x = Conv2D(filters=64,\n",
    "                   kernel_size=(1,1),\n",
    "                   kernel_initializer='he_uniform', \n",
    "                   kernel_regularizer=l2(l2_lambda),\n",
    "                   padding='same', \n",
    "                   activation='linear', data_format=\"channels_last\")(x)\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(x)\n",
    "\n",
    "    # add one layer on flattened output\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.50)(x) # add some dropout for regularization after conv layers\n",
    "    x = Dense(64, \n",
    "              activation='relu',\n",
    "              kernel_initializer='he_uniform',\n",
    "              kernel_regularizer=l2(l2_lambda)\n",
    "            )(x)\n",
    "    \n",
    "    x = Dense(NUM_CLASSES, \n",
    "              activation='relu',\n",
    "              kernel_initializer='he_uniform',\n",
    "              kernel_regularizer=l2(l2_lambda)\n",
    "             )(x)\n",
    "    \n",
    "    # now add this branch onto the master list\n",
    "    branches.append(x)\n",
    "\n",
    "# that's it, we just need to average the results\n",
    "x = concatenate(branches)\n",
    "\n",
    "x = Dense(NUM_CLASSES, \n",
    "          activation='softmax', \n",
    "          kernel_initializer='glorot_uniform',\n",
    "          kernel_regularizer=l2(l2_lambda)\n",
    "         )(x)\n",
    "\n",
    "# here is the secret sauce for setting the network using the \n",
    "#   Functional API:\n",
    "cnn_ens = Model(inputs=input_holder,outputs=x)\n",
    "\n",
    "cnn_ens.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_ens.compile(loss='categorical_crossentropy', # 'categorical_crossentropy' 'mean_squared_error'\n",
    "                optimizer='rmsprop', # 'adadelta' 'rmsprop'\n",
    "                metrics=['acc', f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history2 =cnn_ens.fit_generator(datagen.flow(X_train_d, y_train_ohe, batch_size=128), \n",
    "                  steps_per_epoch=int(len(X_train)/128), # how many generators to go through per epoch\n",
    "                  epochs=50, verbose=1,\n",
    "                  validation_data=(X_test_d,y_test_ohe),\n",
    "                  callbacks=[EarlyStopping(monitor='val_loss', patience=2)]\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "summarize_net(cnn_ens, X_test_d, y_test, title_text='Using Expansion:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xception style architecture\n",
    "from keras.layers import SeparableConv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Add\n",
    "from keras.layers import average, concatenate\n",
    "from keras.models import Input, Model\n",
    "\n",
    "l2_lambda = 0.000001\n",
    "\n",
    "\n",
    "\n",
    "input_holder = Input(shape=(img_wh, img_wh, 1))\n",
    "\n",
    "# start with a conv layer\n",
    "x = Conv2D(filters=32,\n",
    "               input_shape = (img_wh,img_wh,1),\n",
    "               kernel_size=(3,3),\n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda),\n",
    "               padding='same', \n",
    "               activation='relu', \n",
    "               data_format=\"channels_last\")(input_holder)\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(x)\n",
    "\n",
    "x = Conv2D(filters=64,\n",
    "               kernel_size=(3,3),\n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda),\n",
    "               padding='same', \n",
    "               activation='relu', \n",
    "               data_format=\"channels_last\")(x)\n",
    "\n",
    "\n",
    "x_split = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(x)\n",
    "\n",
    "x = SeparableConv2D(filters=64,\n",
    "               input_shape = (img_wh,img_wh,1),\n",
    "               kernel_size=(3,3),\n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda),\n",
    "               padding='same', \n",
    "               activation='relu', \n",
    "               depth_multiplier = 1, # controls output channels\n",
    "               data_format=\"channels_last\")(x_split)\n",
    "\n",
    "\n",
    "x_split = Add()([x, x_split])\n",
    "x_split = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(x_split)\n",
    "\n",
    "\n",
    "x = SeparableConv2D(filters=64,\n",
    "               input_shape = (img_wh,img_wh,1),\n",
    "               kernel_size=(3,3),\n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda),\n",
    "               padding='same', \n",
    "               activation='relu', \n",
    "               depth_multiplier = 1, # controls output channels\n",
    "               data_format=\"channels_last\")(x_split)\n",
    "\n",
    "\n",
    "x_split = Add()([x, x_split])\n",
    "x_split = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(x_split)\n",
    "x_split = SeparableConv2D(filters=128,\n",
    "               input_shape = (img_wh,img_wh,1),\n",
    "               kernel_size=(3,3),\n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda),\n",
    "               padding='same', \n",
    "               activation='relu', \n",
    "               depth_multiplier = 1, # controls output channels\n",
    "               data_format=\"channels_last\")(x_split)\n",
    "x = Activation(\"relu\")(x_split)\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(NUM_CLASSES,activation=\"softmax\")(x)\n",
    "\n",
    "xception = Model(inputs=input_holder,outputs=x)\n",
    "\n",
    "xception.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speed up by training by not using augmentation, perhaps there are faster ways??\n",
    "xception.compile(loss='categorical_crossentropy', # 'categorical_crossentropy' 'mean_squared_error'\n",
    "                optimizer='rmsprop', # 'adadelta' 'rmsprop'\n",
    "                metrics=['acc', f1_m])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history3 =xception.fit_generator(datagen.flow(X_train_d, y_train_ohe, batch_size=32), \n",
    "                  steps_per_epoch=int(len(X_train)/32), # how many generators to go through per epoch\n",
    "                  epochs=50, verbose=1,\n",
    "                  validation_data=(X_test_d,y_test_ohe),\n",
    "                  callbacks=[EarlyStopping(monitor='val_loss', patience=3)]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_net(xception, X_test_d, y_test, title_text='Using Expansion:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Visualize Results\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,11))\n",
    "plt.subplot(2,3,1)\n",
    "plt.ylabel('5 layers CNN acc and val_acc')\n",
    "plt.xlabel('epochs CNN')\n",
    "plt.plot(history.history['f1_m'])\n",
    "\n",
    "plt.plot(history.history['val_f1_m'])\n",
    "\n",
    "\n",
    "plt.subplot(2,3,4)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.ylabel('5 layers CNN acc and val_acc')\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epochs CNN')\n",
    "\n",
    "\n",
    "plt.subplot(2,3,2)\n",
    "plt.ylabel('Ensemble Nets acc and val_acc')\n",
    "plt.xlabel('epochs Ensemble')\n",
    "plt.plot(history2.history['f1_m'])\n",
    "\n",
    "plt.plot(history2.history['val_f1_m'])\n",
    "\n",
    "\n",
    "plt.subplot(2,3,5)\n",
    "plt.plot(history2.history['loss'])\n",
    "plt.ylabel('Ensemble Nets Loss and val_loss')\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.xlabel('epochs Ensemble')\n",
    "\n",
    "plt.subplot(2,3,3)\n",
    "plt.ylabel('Xception Nets acc and val_acc')\n",
    "plt.xlabel('epochs Xception')\n",
    "plt.plot(history3.history['f1_m'])\n",
    "\n",
    "plt.plot(history3.history['val_f1_m'])\n",
    "\n",
    "\n",
    "plt.subplot(2,3,6)\n",
    "plt.plot(history3.history['loss'])\n",
    "plt.ylabel('Xception Nets Loss and val_loss')\n",
    "plt.plot(history3.history['val_loss'])\n",
    "plt.xlabel('epochs Xception')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from the figures above the following, we found out that network in network Ensemble is the best in terms of loss and validation accuract, \n",
    "\n",
    "Xception did the worst in this set even though we have more than 77 thousand parameters to optimize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Comparing CNN Performance with MLP\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as mt\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "def compare_mlp_cnn(cnn, mlp, X_test, y_test):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    if cnn is not None:\n",
    "        X_test_d = np.expand_dims(X_test.reshape((-1,img_wh,img_wh)), axis=3)\n",
    "        yhat_cnn = np.argmax(cnn.predict(X_test_d), axis=1)\n",
    "        acc_cnn = mt.accuracy_score(y_test,yhat_cnn)\n",
    "        plt.subplot(1,2,1)\n",
    "        cm = mt.confusion_matrix(y_test,yhat_cnn)\n",
    "        cm = cm/np.sum(cm,axis=1)[:,np.newaxis]\n",
    "        sns.heatmap(cm, annot=True, fmt='.2f')\n",
    "        plt.title('CNN: '+str(acc_cnn))\n",
    "    \n",
    "    if mlp is not None:\n",
    "        yhat_mlp = np.argmax(mlp.predict(X_test), axis=1)\n",
    "        acc_mlp = mt.accuracy_score(y_test,yhat_mlp)\n",
    "        plt.subplot(1,2,2)\n",
    "        cm = mt.confusion_matrix(y_test,yhat_mlp)\n",
    "        cm = cm/np.sum(cm,axis=1)[:,np.newaxis]\n",
    "        sns.heatmap(cm,annot=True, fmt='.2f')\n",
    "        plt.title('MLP: '+str(acc_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "y_train_ohe = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test_ohe = keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "# make a 3 layer keras MLP\n",
    "mlp = Sequential()\n",
    "mlp.add( Dense(input_dim=X_train.shape[1], units=30, activation='relu') )\n",
    "mlp.add( Dense(units=15, activation='relu') )\n",
    "mlp.add( Dense(NUM_CLASSES) )\n",
    "mlp.add( Activation('softmax') )\n",
    "\n",
    "mlp.compile(loss='mean_squared_error',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "mlp.fit(X_train, y_train_ohe, \n",
    "        batch_size=32, epochs=150, \n",
    "        shuffle=True, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.flatten().shape)\n",
    "\n",
    "compare_mlp_cnn(cnn,mlp,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Exceptional Work: Transfer Learning**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69599, 50, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model, Input\n",
    "from keras.applications.vgg19 import VGG19, decode_predictions, preprocess_input\n",
    "from keras.layers import SeparableConv2D, Add, Flatten, Dense, average, concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from skimage.transform import resize\n",
    "from scipy.misc import imresize\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# copy train and test sets\n",
    "x_train = X_train_d.copy()\n",
    "x_test = X_test_d.copy()\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 50)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.0.0) /io/opencv/modules/imgproc/src/color.hpp:261: error: (-2:Unspecified error) in function 'cv::CvtHelper<VScn, VDcn, VDepth, sizePolicy>::CvtHelper(cv::InputArray, cv::OutputArray, int) [with VScn = cv::Set<1>; VDcn = cv::Set<3, 4>; VDepth = cv::Set<0, 2, 5>; cv::SizePolicy sizePolicy = (cv::SizePolicy)2u; cv::InputArray = const cv::_InputArray&; cv::OutputArray = const cv::_OutputArray&]'\n> Unsupported depth of input image:\n>     'VDepth::contains(depth)'\n> where\n>     'depth' is 4 (CV_32S)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-1691cba3140d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcolor_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_GRAY2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.0.0) /io/opencv/modules/imgproc/src/color.hpp:261: error: (-2:Unspecified error) in function 'cv::CvtHelper<VScn, VDcn, VDepth, sizePolicy>::CvtHelper(cv::InputArray, cv::OutputArray, int) [with VScn = cv::Set<1>; VDcn = cv::Set<3, 4>; VDepth = cv::Set<0, 2, 5>; cv::SizePolicy sizePolicy = (cv::SizePolicy)2u; cv::InputArray = const cv::_InputArray&; cv::OutputArray = const cv::_OutputArray&]'\n> Unsupported depth of input image:\n>     'VDepth::contains(depth)'\n> where\n>     'depth' is 4 (CV_32S)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "a = x_train[0]\n",
    "a = np.resize(a, (50,50))\n",
    "print(a.shape)\n",
    "color_img = cv2.cvtColor(x_train,cv2.COLOR_GRAY2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69599, 50, 50, 1)\n",
      "(69599, 50, 50, 1, 3)\n",
      "(17400, 50, 50, 1)\n",
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 7.63 µs\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_16 to have 4 dimensions, but got array with shape (1, 50, 50, 1, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-c54b6bfe3aa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlenv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                              'argument.')\n\u001b[1;32m   1148\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlenv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlenv/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_16 to have 4 dimensions, but got array with shape (1, 50, 50, 1, 3)"
     ]
    }
   ],
   "source": [
    "# upsample images\n",
    "#x_train_up = [imresize(x, size=(50,50,3), interp='nearest') for x in x_train]\n",
    "x_train_up = [resize(x, (50,50,1), anti_aliasing=True) for x in x_train]\n",
    "x_train_up = np.stack(x_train_up, axis=0)\n",
    "print(x_train_up.shape)\n",
    "x_train_up = np.stack([x_train_up[1]]*3, axis=-1)\n",
    "print(x_train_up.shape)\n",
    "\n",
    "#x_test_up = [imresize(x, size=(50,50,3), interp='nearest') for x in x_test]\n",
    "x_test_up = [resize(x, (50,50,1), anti_aliasing=True) for x in x_test]\n",
    "x_test_up = np.stack(x_test_up, axis=0)\n",
    "print(x_test_up.shape) \n",
    "\n",
    "model = VGG19(include_top=False, weights='imagenet')\n",
    "\n",
    "x = x_train_up[0]\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "%time \n",
    "preds = model.predict(x)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_up = preprocess_input(x_train_up)\n",
    "x_test_up = preprocess_input(x_test_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69599, 1, 1, 512)\n",
      "CPU times: user 1h 48min 6s, sys: 5min 12s, total: 1h 53min 19s\n",
      "Wall time: 16min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "x_train_vgg = model.predict(x_train_up)\n",
    "x_test_vgg = model.predict(x_test_up)\n",
    "print(x_train_vgg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               51300     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 29)                2929      \n",
      "=================================================================\n",
      "Total params: 54,229\n",
      "Trainable params: 54,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# x_train_vgg2 = StandardScaler().fit(x_train_vgg).transform(x_train_vgg)\n",
    "# x_test_vgg2 = StandardScaler().fit(x_test_vgg).transform(x_test_vgg)\n",
    "\n",
    "# print(x_train_vgg2.shape)\n",
    "\n",
    "# X_train_d =np.expand_dims(x_train_vgg.reshape((-1,2500)), axis=0)\n",
    "# X_test_d =np.expand_dims(X_test_vgg.reshape((-1,2500)), axis=0)\n",
    "\n",
    "# print(X_train_d.shape)\n",
    "\n",
    "input_x = Input(shape=x_train_vgg[0].shape)\n",
    "x = Flatten()(input_x)\n",
    "\n",
    "x = Dense(100, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax', kernel_initializer='glorot_uniform')(x)\n",
    "\n",
    "model2 = Model(inputs=input_x, outputs=predictions)\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 69599 samples, validate on 17400 samples\n",
      "Epoch 1/10\n",
      "69599/69599 [==============================] - 4s 56us/step - loss: 3.4264 - acc: 0.0343 - f1_m: 0.0000e+00 - val_loss: 3.3678 - val_acc: 0.0337 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/10\n",
      "69599/69599 [==============================] - 3s 49us/step - loss: 3.3677 - acc: 0.0337 - f1_m: 0.0000e+00 - val_loss: 3.3677 - val_acc: 0.0322 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/10\n",
      "69599/69599 [==============================] - 3s 50us/step - loss: 3.3678 - acc: 0.0347 - f1_m: 0.0000e+00 - val_loss: 3.3676 - val_acc: 0.0322 - val_f1_m: 0.0000e+00\n",
      "Epoch 4/10\n",
      "69599/69599 [==============================] - 3s 49us/step - loss: 3.3676 - acc: 0.0341 - f1_m: 0.0000e+00 - val_loss: 3.3676 - val_acc: 0.0322 - val_f1_m: 0.0000e+00\n",
      "Epoch 5/10\n",
      "69599/69599 [==============================] - 3s 50us/step - loss: 3.3677 - acc: 0.0333 - f1_m: 0.0000e+00 - val_loss: 3.3677 - val_acc: 0.0329 - val_f1_m: 0.0000e+00\n",
      "Epoch 6/10\n",
      "69599/69599 [==============================] - 3s 50us/step - loss: 3.3677 - acc: 0.0343 - f1_m: 0.0000e+00 - val_loss: 3.3676 - val_acc: 0.0322 - val_f1_m: 0.0000e+00\n",
      "Epoch 7/10\n",
      "69599/69599 [==============================] - 3s 50us/step - loss: 3.3677 - acc: 0.0336 - f1_m: 0.0000e+00 - val_loss: 3.3676 - val_acc: 0.0328 - val_f1_m: 0.0000e+00\n",
      "Epoch 8/10\n",
      "69599/69599 [==============================] - 4s 51us/step - loss: 3.3677 - acc: 0.0334 - f1_m: 0.0000e+00 - val_loss: 3.3677 - val_acc: 0.0328 - val_f1_m: 0.0000e+00\n",
      "Epoch 9/10\n",
      "69599/69599 [==============================] - 4s 51us/step - loss: 3.3676 - acc: 0.0353 - f1_m: 0.0000e+00 - val_loss: 3.3677 - val_acc: 0.0329 - val_f1_m: 0.0000e+00\n",
      "Epoch 10/10\n",
      "69599/69599 [==============================] - 4s 51us/step - loss: 3.3677 - acc: 0.0329 - f1_m: 0.0000e+00 - val_loss: 3.3677 - val_acc: 0.0326 - val_f1_m: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdaa54e7e48>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_ohe_vgg = y_train_ohe[:x_train_vgg.shape[0]]\n",
    "\n",
    "model2.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc', f1_m])\n",
    "\n",
    "model2.fit(x_train_vgg, y_train_ohe_vgg, \n",
    "           epochs=10, batch_size=32, verbose=1, \n",
    "           validation_data=(x_test_vgg, y_test_ohe[:x_test_vgg.shape[0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarize_net(model2, x_test_vgg, y_test[:x_test_vgg.shape[0]], title_text='Transfer Learning, VGG19:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. References**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
